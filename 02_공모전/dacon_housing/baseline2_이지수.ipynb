{"cells":[{"cell_type":"markdown","id":"ca6e7384-49f5-4b7c-986b-e8f686e80fd4","metadata":{"id":"ca6e7384-49f5-4b7c-986b-e8f686e80fd4"},"source":["# 데이터 불러오기\n","필요한 패키지를 임포트하고 데이터를 불러와줍니다."]},{"cell_type":"code","execution_count":null,"id":"5b9b0374-2844-4877-a850-0e2158f4901a","metadata":{"id":"5b9b0374-2844-4877-a850-0e2158f4901a","outputId":"2acab571-805f-41ec-ac25-8d216868d5bb"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Overall Qual</th>\n","      <th>Gr Liv Area</th>\n","      <th>Exter Qual</th>\n","      <th>Garage Cars</th>\n","      <th>Garage Area</th>\n","      <th>Kitchen Qual</th>\n","      <th>Total Bsmt SF</th>\n","      <th>1st Flr SF</th>\n","      <th>Bsmt Qual</th>\n","      <th>Full Bath</th>\n","      <th>Year Built</th>\n","      <th>Year Remod/Add</th>\n","      <th>Garage Yr Blt</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>2392</td>\n","      <td>Ex</td>\n","      <td>3</td>\n","      <td>968</td>\n","      <td>Ex</td>\n","      <td>2392</td>\n","      <td>2392</td>\n","      <td>Ex</td>\n","      <td>2</td>\n","      <td>2003</td>\n","      <td>2003</td>\n","      <td>2003</td>\n","      <td>386250</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>1352</td>\n","      <td>Gd</td>\n","      <td>2</td>\n","      <td>466</td>\n","      <td>Gd</td>\n","      <td>1352</td>\n","      <td>1352</td>\n","      <td>Ex</td>\n","      <td>2</td>\n","      <td>2006</td>\n","      <td>2007</td>\n","      <td>2006</td>\n","      <td>194000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>900</td>\n","      <td>TA</td>\n","      <td>1</td>\n","      <td>288</td>\n","      <td>TA</td>\n","      <td>864</td>\n","      <td>900</td>\n","      <td>TA</td>\n","      <td>1</td>\n","      <td>1967</td>\n","      <td>1967</td>\n","      <td>1967</td>\n","      <td>123000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>1174</td>\n","      <td>TA</td>\n","      <td>2</td>\n","      <td>576</td>\n","      <td>Gd</td>\n","      <td>680</td>\n","      <td>680</td>\n","      <td>TA</td>\n","      <td>1</td>\n","      <td>1900</td>\n","      <td>2006</td>\n","      <td>2000</td>\n","      <td>135000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>1958</td>\n","      <td>Gd</td>\n","      <td>3</td>\n","      <td>936</td>\n","      <td>Gd</td>\n","      <td>1026</td>\n","      <td>1026</td>\n","      <td>Gd</td>\n","      <td>2</td>\n","      <td>2005</td>\n","      <td>2005</td>\n","      <td>2005</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  Overall Qual  Gr Liv Area Exter Qual  Garage Cars  Garage Area  \\\n","0   1            10         2392         Ex            3          968   \n","1   2             7         1352         Gd            2          466   \n","2   3             5          900         TA            1          288   \n","3   4             5         1174         TA            2          576   \n","4   5             7         1958         Gd            3          936   \n","\n","  Kitchen Qual  Total Bsmt SF  1st Flr SF Bsmt Qual  Full Bath  Year Built  \\\n","0           Ex           2392        2392        Ex          2        2003   \n","1           Gd           1352        1352        Ex          2        2006   \n","2           TA            864         900        TA          1        1967   \n","3           Gd            680         680        TA          1        1900   \n","4           Gd           1026        1026        Gd          2        2005   \n","\n","   Year Remod/Add  Garage Yr Blt  target  \n","0            2003           2003  386250  \n","1            2007           2006  194000  \n","2            1967           1967  123000  \n","3            2006           2000  135000  \n","4            2005           2005  250000  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# (참고) import pandas as pd   * pandas : 데이터 처리, 분석 라이브러리 \n","#import numpy as np  * numpy : 대규모 다차원 배열, 행렬연산에 필요한 라이브러리 \n","#import matplotlib.pyplot as plt  * matplotlib : Python 프로그래밍 언어 및 수학적 확장 NumPy 라이브러리를 활용한 플로팅 라이브러리\n","#import seaborn as sns  * seaborn : 데이터 시각화 담당 라이브러리\n","#from scipy import stats  * SciPy : 파이썬을 기반으로 하여 과학, 분석, 그리고 엔지니어링을 위한 과학(계산)적 컴퓨팅 영역의 여러 기본적인 작업을 위한 라이브러리(패키지 모음)\n","\n","\n","import warnings #*warning  라이브러리를 사용해서\n","warnings.filterwarnings(action='ignore') # 경고 메세지를 무시하고 숨기기\n","\n","import pandas as pd \n","\n","train_data = pd.read_csv(\"./data/train.csv\")  # 훈련 데이터 csv파일 읽어오기\n","sample_submission = pd.read_csv(\"./data/sample_submission.csv\") # sample_submission.csv 파일 읽어오기\n","\n","train_data.head() # 훈련 데이터의 앞의 5개의 정보만 출력해서 보여주기 "]},{"cell_type":"markdown","id":"03004945-6c91-49ec-a1c0-024cf61aac8a","metadata":{"id":"03004945-6c91-49ec-a1c0-024cf61aac8a"},"source":["출력된 데이터의 모양을 살펴보면 총 15개의 열(column)이 존재하는 것을 확인할 수 있습니다.\n","\n","15 개 중 2개는 id 와 target 열 입니다.\n","\n","데이터를 자세히 살펴보는 것은 EDA 글을 통해 더 자세히 배워봅시다.\n","\n","여기에서는 분석 방법에 초점을 맞추겠습니다.\n","\n","데이터를 살펴보면 데이터의 모양이 조금씩 다릅니다.\n","\n","Gr Liv Area, Garage Cars 과 같은 데이터들은 수치를 나타내는 데이터로 수치형(numerical) 데이터라고 합니다.\n","\n","반면, Kitchen Qual, Bsmt Qual 와 같은 데이터는 수치가 아닌 종류를 나타내죠. 이러한 데이터를 범주형(categorical) 데이터라고 합니다.\n","\n","범주형 데이터의 라벨이 숫자가 아닌 문자열의 형식으로 저장되어 있다면 데이터 분석 과정에서 인코딩(encoding)이 필요합니다."]},{"cell_type":"markdown","id":"81796818-701f-405c-9f80-568015b69fe9","metadata":{"id":"81796818-701f-405c-9f80-568015b69fe9"},"source":["## 결측치 확인\n","\n","결측치(NA: Not Available)란 값이 누락된 데이터를 말합니다.\n","\n","보다 정확한 분석을 하기 위해서는 데이터의 결측치를 확인하고 적절히 처리해주어야 합니다.\n","\n","이번 데이터에 결측치가 있나 확인해볼까요?"]},{"cell_type":"code","execution_count":null,"id":"85adad87-2c61-42b9-92a4-184cb5dcce76","metadata":{"id":"85adad87-2c61-42b9-92a4-184cb5dcce76","outputId":"f8d55671-d849-443a-bf46-f3a18ff02cf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["결측치가 존재하지 않습니다\n"]}],"source":["def check_missing_col(dataframe): # baselne 1에서와 같이 결측치를 확인하는 함수 \n","    missing_col = []  \n","    counted_missing_col = 0\n","    for i, col in enumerate(dataframe.columns):\n","        missing_values = sum(dataframe[col].isna())\n","        is_missing = True if missing_values >= 1 else False\n","        if is_missing:\n","            counted_missing_col += 1\n","            print(f'결측치가 있는 컬럼은: {col}입니다')\n","            print(f'해당 컬럼에 총 {missing_values}개의 결측치가 존재합니다.')\n","            missing_col.append([col, dataframe[col].dtype])\n","    if counted_missing_col == 0:\n","        print('결측치가 존재하지 않습니다')\n","    return missing_col\n","\n","missing_col = check_missing_col(train_data)"]},{"cell_type":"markdown","id":"93eb017c-8fac-4292-9738-b2aa0455b9e9","metadata":{"id":"93eb017c-8fac-4292-9738-b2aa0455b9e9"},"source":["### 라벨 인코딩\n","라벨인코더를 이용해 라벨인코딩을 진행해주려 합니다.\n","\n","라벨인코딩이란, 범주형 변수를 숫자로 인코딩해주는 동시에 컴퓨터가 이들이 각각 다른 범주인 것을 인식하도록 각 값을 0, 1, 2 등의 값으로 구별하여 인코딩하는 기법을 말합니다.\n","\n","라벨 인코딩 함수를 작성해 직접 변수들을 인코딩하겠습니다."]},{"cell_type":"code","execution_count":null,"id":"c06d75f4-0771-41e7-9339-35000e056215","metadata":{"id":"c06d75f4-0771-41e7-9339-35000e056215"},"outputs":[],"source":["#라벨 인코딩을 하기 전 불필요한 열을 제거하고, 범주형 데이터 열과 수치형 데이터 열을 나누어줍니다. \n","train_x = train_data.drop([\"id\",\"target\"],axis=1) # 불필요한 데이터 id와 target 열 제거\n","train_y = train_data.target \n","\n","num_features = ['Overall Qual', 'Gr Liv Area', 'Garage Cars',  # 수치형 데이터 열\n","       'Garage Area', 'Total Bsmt SF', '1st Flr SF',\n","       'Full Bath', 'Year Built', 'Year Remod/Add',\n","       'Garage Yr Blt']\n","\n","cat_features = [\"Exter Qual\", \"Kitchen Qual\",\"Bsmt Qual\"] # 범주형 데이터 열\n"," \n","from sklearn.preprocessing import LabelEncoder # 라벨인코딩 기능을 사용하기 위해서 sklearn의 preprocessing의 LabelEncoder를 import \n","#(사이킷런은 파이썬에서 머신러닝 분석을 할 때 유용하게 사용할 수 있는 라이브러리/ 여러가지 머신러닝 모듈로 구성)\n","\n","le = LabelEncoder()\n","\n","for feature in cat_features:\n","    train_x[feature] = le.fit_transform(train_x[feature])  # train_x[feature]의 데이터를 기준으로 수치화하는 코드이다. "]},{"cell_type":"markdown","id":"f6225ac3-021f-49be-9bd5-c993a04ce0ad","metadata":{"id":"f6225ac3-021f-49be-9bd5-c993a04ce0ad"},"source":["### 정규화 \n","수치형 데이터들을 정규화 시켜줍니다.\n","\n","머신러닝 과정에서 모델은 데이터의 특성(feature)들을 추출해 학습을 진행합니다.\n","\n","하지만 학습을 하는 과정에서 데이터의 값이 너무 크거나, 분산이 너무 크면 학습 과정에 악영향을 끼칠 수 있습니다. \n","\n","따라서 정규화를 통해 데이터 값의 크기를 줄이고 분산을 줄여 모델이 데이터를 이상하게 해석하는 것을 방지합니다.\n","\n","이번 베이스라인에서는 min-max 정규화를 이용해 봅시다.\n","\n","min-max 정규화는 수치형 데이터의 값을 0~1 사이의 값으로 변환해줍니다.\n","\n","min-max 정규화의 수식은 아래와 같습니다.\n","\n","X' = (X - MIN) / (MAX-MIN)"]},{"cell_type":"code","execution_count":null,"id":"b82f27c5-8de6-431a-91f4-32c3dfe86071","metadata":{"id":"b82f27c5-8de6-431a-91f4-32c3dfe86071"},"outputs":[],"source":["#정규화를 위한 패키지를 불러옵니다.\n","from sklearn.preprocessing import MinMaxScaler\n","\n","#수치형 데이터를 정규화 시켜줍니다.\n","scaler = MinMaxScaler()\n","train_x[num_features] = scaler.fit_transform(train_x[num_features])"]},{"cell_type":"markdown","id":"d056a695-601d-44e9-a0b1-2ac73683345a","metadata":{"id":"d056a695-601d-44e9-a0b1-2ac73683345a"},"source":["### 모델 설계 & 학습\n","\n","#### GridSearchCV 를 사용한 파라미터 최적화\n","\n","이제 데이터를 전처리하는 과정이 끝났습니다. 이제 데이터 분석을 위해 모델을 설계하는 단계를 진행해야 합니다.\n","\n","우선 사용할 모델을 선택하여야 합니다. 사용할 모델은 데이터의 특성, task 의 특성에 알맞게 선택해야 합니다.\n","\n","모델을 선택했다면 모델의 파라미터를 최적화하는 과정을 거쳐야 합니다. \n","\n","파라미터란 모델의 설정을 말합니다. 예를 들어 Linear Regression 모델의 경우 y 절편을 0으로 설정할 수 있습니다.\n","\n","파라미터 최적화를 하는 기본적인 방법은 여러 파라미터들을 실험하는 방법입니다.\n","\n","sklearn 은 GridSearchCV 메소드를 제공합니다.\n","\n","우선 선택한 모델과 비교하고 싶은 파라미터들을 설정해 줍니다. \n","\n","그 다음 학습 데이터를 나누어줍니다. 예를 들어 학습 데이터를 5개의 배치로 나누어 주었다고 가정 해보겠습니다.\n","\n","5개로 나누어진 데이터 중, 4개의 데이터로 학습을 진행합니다. 그 다음 나머지 1개의 데이터 배치로 성능을 검증합니다.\n","\n","따라서 5번의 학습과 검증이 이루어질 것 입니다. 이때 최상의 성능을 출력하는 파라미터들이 모델의 파라미터로 선택되는 것 입니다.\n","\n","데이터를 n개의 배치로 나누고, 비교하고자 하는 파라미터들의 조합이 m개라면 총 n * m 번의 학습과 검증이 진행되는 것 입니다.\n","\n","따라서 학습 시간이 오래 걸리고, 그에 맞는 컴퓨팅 자원이 필요합니다.\n","\n","이번 베이스라인에서는 GridSearchCV 기법의 개념을 소개하는 방향으로 작성되었습니다.\n","\n","따라서 앙상블 기법에 사용된 세부적인 모델들의 세부적인 개념들을 추후 베이스라인들에서 소개하겠습니다."]},{"cell_type":"code","execution_count":null,"id":"97ccd75e-30d7-49ca-880e-86034bdd1ece","metadata":{"id":"97ccd75e-30d7-49ca-880e-86034bdd1ece"},"outputs":[],"source":["#GridSearchCV 를 사용할 모델들을 호출합니다.\n","from sklearn.ensemble import RandomForestRegressor # 랜덤포레스트는 dataset의 다양한 하위 sample에 대한 여러 개의 Decision Tree에서의 평균을 사용하여 predict Accuracy를 높이고 overffing을 제어하는 meta estimator \n","from sklearn.ensemble import GradientBoostingRegressor # 앙상블 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가하지만 이전 예측기가 만든 잔여오차에 새로운 예측기를 학습시킴\n","from sklearn.ensemble import ExtraTreesRegressor # 데이터 세트의 다양한 하위 샘플에 여러 무작위 결정 트리(extra-trees라고도 함)에 맞는 메타 추정기를 구현하고 평균을 사용하여 예측 정확도를 개선하고 과적합을 제어\n","from sklearn.model_selection import GridSearchCV # GridSearchCV:사이킷런에서는 분류 알고리즘이나 회귀 알고리즘에 사용되는 하이퍼파라미터를 순차적으로 입력해 학습을 하고 측정을 하면서 가장 좋은 파라미터를 알려줌\n","\n","#모델들을 할당할 리스트를 만들어줍니다.\n","estimators = []\n","\n","#estimators 리스트에 모델들을 추가해줍니다.\n","rf = RandomForestRegressor()\n","estimators.append(rf)\n","\n","gbr = GradientBoostingRegressor()\n","estimators.append(gbr)\n","\n","etr = ExtraTreesRegressor()\n","estimators.append(etr)\n","\n","#모들의 파라미터들을 할당할 리스트를 만들어줍니다.\n","params = []\n","\n","# params 리스트에 성능을 비교하고자하는 파라미터들 추가해줍니다.\n","params_rf = {'n_estimators' : [90, 100, 110, 120],\n","            'min_samples_split' : [1,2,3,4]}\n","params.append(params_rf)\n","\n","params_gbr = {'loss' : ['huber', 'quantile'],\n","             'learning_rate':[0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15],\n","             'n_estimators':[60,70,80,90,100,110,120,130,140,150]}\n","params.append(params_gbr)\n","\n","params_etr = {'n_estimators' : [50,60,70,80,90,100,110,120,130,140,150]}\n","params.append(params_etr)"]},{"cell_type":"code","execution_count":null,"id":"ae20071a-34e4-47b9-acc6-31409c54a063","metadata":{"colab":{"referenced_widgets":["56024a010fda4a4e8b62d7d6d2a506a5"]},"id":"ae20071a-34e4-47b9-acc6-31409c54a063","outputId":"142c789b-b2b4-46db-b12b-a901b9a9e45d"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56024a010fda4a4e8b62d7d6d2a506a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.9s\n","[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    3.4s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 220 candidates, totalling 1100 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.6s\n","[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    3.9s\n","[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    9.3s\n","[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   16.9s\n","[Parallel(n_jobs=-1)]: Done 1100 out of 1100 | elapsed:   24.2s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.5s\n","[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.5s finished\n"]}],"source":["#GridSearchCV 를 이용해 모델들을 최적화시켜줍니다.\n","from tqdm.auto import tqdm # 파이썬으로 어떤 작업을 수행 중일 때, 프로그램이 내가 의도한 대로 돌아가고 있는 중인지 확인할 수 있음\n","def gridSearchCV(models,params):\n","    best_models=[]\n","    for i in tqdm(range(0,len(models))):\n","        model_grid = GridSearchCV(models[i], params[i],n_jobs = -1, verbose=1, cv=5)\n","        model_grid.fit(train_x,train_y)\n","        best_models.append(model_grid.best_estimator_)\n","    return best_models\n","\n","best_model_list = gridSearchCV(estimators,params)"]},{"cell_type":"code","execution_count":null,"id":"5c1b0370-4788-446a-bcd4-8e54fcd3b8a4","metadata":{"id":"5c1b0370-4788-446a-bcd4-8e54fcd3b8a4","outputId":"e4e06cd3-015f-47cb-8142-078d195c7571"},"outputs":[{"data":{"text/plain":["[RandomForestRegressor(n_estimators=90),\n"," GradientBoostingRegressor(learning_rate=0.09, loss='huber', n_estimators=150),\n"," ExtraTreesRegressor(n_estimators=110)]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#GridSerachCV 를 통해 최적화된 모델들을 확인합니다.\n","best_model_list"]},{"cell_type":"markdown","id":"7fe36741-d655-4a3a-a06d-522a684d49d7","metadata":{"id":"7fe36741-d655-4a3a-a06d-522a684d49d7"},"source":["#### 앙상블 모델 학습\n","\n","위 코드에서는 3개의 모델을 선택하여 GridSearchCV 를 통해 각 모델들의 파라미터들을 최적화해주었습니다.\n","\n","그 다음에는 3개의 모델을 모두 활용하여 하나의 모델을 설계해 보겠습니다.\n","\n","앙살블 기법은 \"집단지성\" 으로 부터 아이디어를 얻은 알고리즘입니다.\n"," \n","모델 하나의 예측 보다는 여러 모델들의 예측을 종합하여 도출한 예측이 더 정확할 때가 많습니다. \n","\n","Regression 의 경우 각 모델들이 개별로 예측한 값의 평균 값을 도출하는 방식으로 여러 모델들을 조합해줍니다.\n","\n","sklearn 패키지의 VotingRegressor 메소드를 통해 앙상블 모델을 구현할 수 있습니다.\n","\n","GridSearchCV 를 통해 최적의 파라미터들을 찾은 모델들 VotingRegressor 객체에 할당한 후, 학습을 진행합니다.\n","\n","이번 베이스라인에서는 앙상블 기법의 개념을 소개하는 방향으로 작성되었습니다.\n","\n","따라서 앙상블 기법에 사용된 세부적인 모델들의 세부적인 개념들을 추후 베이스라인들에서 소개하겠습니다."]},{"cell_type":"code","execution_count":null,"id":"19cc264b-70f5-4009-9650-a11fac507e83","metadata":{"id":"19cc264b-70f5-4009-9650-a11fac507e83","outputId":"65a6b748-48b4-449d-d9df-4e28e5fb852e"},"outputs":[{"data":{"text/plain":["VotingRegressor(estimators=[('rf',\n","                             RandomForestRegressor(min_samples_split=3,\n","                                                   n_estimators=120)),\n","                            ('GBR',\n","                             GradientBoostingRegressor(learning_rate=0.09,\n","                                                       loss='huber',\n","                                                       n_estimators=130)),\n","                            ('ET', ExtraTreesRegressor(n_estimators=90))])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#GridSearchCV 를 통해 최적화된 모델들을 사용합니다.\n","best_models = [\n","    ('rf', RandomForestRegressor(min_samples_split=3, n_estimators=120)),\n","    ('GBR', GradientBoostingRegressor(learning_rate=0.09, loss='huber', n_estimators=130)),\n","    ('ET', ExtraTreesRegressor(n_estimators=90))\n","]\n","\n","#앙상블 기법을 위한 패키지를 불러옵니다.\n","from sklearn.ensemble import VotingRegressor\n","\n","#앙상블 모델을 학습시켜줍니다.\n","voting_rg = VotingRegressor(estimators=best_models)\n","voting_rg.fit(train_x,train_y)"]},{"cell_type":"markdown","id":"eca202e9-40ba-4250-bc1b-8faf0fbad273","metadata":{"id":"eca202e9-40ba-4250-bc1b-8faf0fbad273"},"source":["### 추론\n","\n","학습 데이터에 했던 전처리 과정(라벨인코딩, 정규화)를 테스트 데이터에도 해줍니다.\n","\n","단, 학습 데이터에 학습된 인코더와 정규화 파라미터를 사용해 주어야 합니다. \n","\n","(테스트 데이터를 학습 시킨 후 인코딩과 정규화를 진행하면 data leakage 에 해당됩니다!)"]},{"cell_type":"code","execution_count":null,"id":"ace9085a-4598-4674-b3ea-f0e540e0ca29","metadata":{"id":"ace9085a-4598-4674-b3ea-f0e540e0ca29"},"outputs":[],"source":["test_data = pd.read_csv(\"./data/test.csv\")\n","\n","test_x = test_data.drop(\"id\",axis=1)\n","\n","for feature in cat_features:\n","    test_x[feature] = le.transform(test_x[feature])\n","    \n","test_x[num_features] = scaler.transform(test_x[num_features])"]},{"cell_type":"code","execution_count":null,"id":"6ea6a30c-1858-435d-b839-9d01bcaa3a6b","metadata":{"id":"6ea6a30c-1858-435d-b839-9d01bcaa3a6b"},"outputs":[],"source":["#학습된 모델을 통해 test 데이터를 추론합니다.\n","predictions = voting_rg.predict(test_x)\n","\n","sample_submission.target = predictions\n","sample_submission.to_csv(\"submission.csv\",index = False)"]}],"metadata":{"interpreter":{"hash":"767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"},"kernelspec":{"display_name":"soobin","language":"python","name":".env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"baseline2이지수.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}