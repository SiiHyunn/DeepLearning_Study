{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6e7384-49f5-4b7c-986b-e8f686e80fd4",
   "metadata": {},
   "source": [
    "# 데이터 불러오기\n",
    "필요한 패키지를 임포트하고 데이터를 불러와줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b9b0374-2844-4877-a850-0e2158f4901a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2392</td>\n",
       "      <td>Ex</td>\n",
       "      <td>3</td>\n",
       "      <td>968</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2392</td>\n",
       "      <td>2392</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>386250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1352</td>\n",
       "      <td>Gd</td>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1352</td>\n",
       "      <td>1352</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>TA</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>TA</td>\n",
       "      <td>864</td>\n",
       "      <td>900</td>\n",
       "      <td>TA</td>\n",
       "      <td>1</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "      <td>123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1174</td>\n",
       "      <td>TA</td>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>Gd</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>TA</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1958</td>\n",
       "      <td>Gd</td>\n",
       "      <td>3</td>\n",
       "      <td>936</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>Gd</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Overall Qual  Gr Liv Area Exter Qual  Garage Cars  Garage Area  \\\n",
       "0   1            10         2392         Ex            3          968   \n",
       "1   2             7         1352         Gd            2          466   \n",
       "2   3             5          900         TA            1          288   \n",
       "3   4             5         1174         TA            2          576   \n",
       "4   5             7         1958         Gd            3          936   \n",
       "\n",
       "  Kitchen Qual  Total Bsmt SF  1st Flr SF Bsmt Qual  Full Bath  Year Built  \\\n",
       "0           Ex           2392        2392        Ex          2        2003   \n",
       "1           Gd           1352        1352        Ex          2        2006   \n",
       "2           TA            864         900        TA          1        1967   \n",
       "3           Gd            680         680        TA          1        1900   \n",
       "4           Gd           1026        1026        Gd          2        2005   \n",
       "\n",
       "   Year Remod/Add  Garage Yr Blt  target  \n",
       "0            2003           2003  386250  \n",
       "1            2007           2006  194000  \n",
       "2            1967           1967  123000  \n",
       "3            2006           2000  135000  \n",
       "4            2005           2005  250000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') #경고 메세지 숨김\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "sample_submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6445f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>334882.884420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>129592.737027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>178400.352033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>242803.337597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>131132.350176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         target\n",
       "0   1  334882.884420\n",
       "1   2  129592.737027\n",
       "2   3  178400.352033\n",
       "3   4  242803.337597\n",
       "4   5  131132.350176"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head() #제출용 csv파일. 0으로 처리되어있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03004945-6c91-49ec-a1c0-024cf61aac8a",
   "metadata": {},
   "source": [
    "출력된 데이터의 모양을 살펴보면 총 15개의 열(column)이 존재하는 것을 확인할 수 있습니다.\n",
    "\n",
    "15 개 중 2개는 id 와 target 열 입니다.\n",
    "\n",
    "데이터를 자세히 살펴보는 것은 EDA 글을 통해 더 자세히 배워봅시다.\n",
    "\n",
    "여기에서는 분석 방법에 초점을 맞추겠습니다.\n",
    "\n",
    "데이터를 살펴보면 데이터의 모양이 조금씩 다릅니다.\n",
    "\n",
    "Gr Liv Area, Garage Cars 과 같은 데이터들은 수치를 나타내는 데이터로 수치형(numerical) 데이터라고 합니다.\n",
    "\n",
    "반면, Kitchen Qual, Bsmt Qual 와 같은 데이터는 수치가 아닌 종류를 나타내죠. 이러한 데이터를 범주형(categorical) 데이터라고 합니다.\n",
    "\n",
    "범주형 데이터의 라벨이 숫자가 아닌 문자열의 형식으로 저장되어 있다면 데이터 분석 과정에서 인코딩(encoding)이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81796818-701f-405c-9f80-568015b69fe9",
   "metadata": {},
   "source": [
    "## 결측치 확인\n",
    "\n",
    "결측치(NA: Not Available)란 값이 누락된 데이터를 말합니다.\n",
    "\n",
    "보다 정확한 분석을 하기 위해서는 데이터의 결측치를 확인하고 적절히 처리해주어야 합니다.\n",
    "\n",
    "이번 데이터에 결측치가 있나 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85adad87-2c61-42b9-92a4-184cb5dcce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치가 존재하지 않습니다\n"
     ]
    }
   ],
   "source": [
    "def check_missing_col(dataframe): #baseline_01에서 봤던 같은 함수\n",
    "    missing_col = []  \n",
    "    counted_missing_col = 0\n",
    "    for i, col in enumerate(dataframe.columns):\n",
    "        missing_values = sum(dataframe[col].isna())\n",
    "        is_missing = True if missing_values >= 1 else False\n",
    "        if is_missing:\n",
    "            counted_missing_col += 1\n",
    "            print(f'결측치가 있는 컬럼은: {col}입니다')\n",
    "            print(f'해당 컬럼에 총 {missing_values}개의 결측치가 존재합니다.')\n",
    "            missing_col.append([col, dataframe[col].dtype])\n",
    "    if counted_missing_col == 0:\n",
    "        print('결측치가 존재하지 않습니다')\n",
    "    return missing_col\n",
    "\n",
    "missing_col = check_missing_col(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb017c-8fac-4292-9738-b2aa0455b9e9",
   "metadata": {},
   "source": [
    "### 라벨 인코딩\n",
    "라벨인코더를 이용해 라벨인코딩을 진행해주려 합니다.\n",
    "\n",
    "라벨인코딩이란, 범주형 변수를 숫자로 인코딩해주는 동시에 컴퓨터가 이들이 각각 다른 범주인 것을 인식하도록 각 값을 0, 1, 2 등의 값으로 구별하여 인코딩하는 기법을 말합니다.\n",
    "\n",
    "라벨 인코딩 함수를 작성해 직접 변수들을 인코딩하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c06d75f4-0771-41e7-9339-35000e056215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨 인코딩을 하기 전 불필요한 열을 제거하고, 범주형 데이터 열과 수치형 데이터 열을 나누어줍니다. \n",
    "train_x = train_data.drop([\"id\",\"target\"],axis=1) #타겟열과 id열을 drop\n",
    "train_y = train_data.target\n",
    "\n",
    "num_features = ['Overall Qual', 'Gr Liv Area', 'Garage Cars', #수치형 데이터\n",
    "       'Garage Area', 'Total Bsmt SF', '1st Flr SF',\n",
    "       'Full Bath', 'Year Built', 'Year Remod/Add',\n",
    "       'Garage Yr Blt'] \n",
    "\n",
    "cat_features = [\"Exter Qual\", \"Kitchen Qual\",\"Bsmt Qual\"] #문자형 데이터\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for feature in cat_features:\n",
    "    train_x[feature] = le.fit_transform(train_x[feature]) #문자형 데이터를 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7df38661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       2\n",
      "2       3\n",
      "3       3\n",
      "4       2\n",
      "       ..\n",
      "1345    2\n",
      "1346    2\n",
      "1347    3\n",
      "1348    3\n",
      "1349    3\n",
      "Name: Exter Qual, Length: 1350, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_x['Exter Qual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6225ac3-021f-49be-9bd5-c993a04ce0ad",
   "metadata": {},
   "source": [
    "### 정규화 \n",
    "수치형 데이터들을 정규화 시켜줍니다.\n",
    "\n",
    "머신러닝 과정에서 모델은 데이터의 특성(feature)들을 추출해 학습을 진행합니다.\n",
    "\n",
    "하지만 학습을 하는 과정에서 데이터의 값이 너무 크거나, 분산이 너무 크면 학습 과정에 악영향을 끼칠 수 있습니다. \n",
    "\n",
    "따라서 정규화를 통해 데이터 값의 크기를 줄이고 분산을 줄여 모델이 데이터를 이상하게 해석하는 것을 방지합니다.\n",
    "\n",
    "이번 베이스라인에서는 min-max 정규화를 이용해 봅시다.\n",
    "\n",
    "min-max 정규화는 수치형 데이터의 값을 0~1 사이의 값으로 변환해줍니다.\n",
    "\n",
    "min-max 정규화의 수식은 아래와 같습니다.\n",
    "\n",
    "X' = (X - MIN) / (MAX-MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b82f27c5-8de6-431a-91f4-32c3dfe86071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화를 위한 패키지를 불러옵니다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#수치형 데이터를 정규화 시켜줍니다.\n",
    "scaler = MinMaxScaler()\n",
    "train_x[num_features] = scaler.fit_transform(train_x[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea1aff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.478478\n",
       "1       0.218218\n",
       "2       0.105105\n",
       "3       0.173674\n",
       "4       0.369870\n",
       "          ...   \n",
       "1345    0.319319\n",
       "1346    0.567568\n",
       "1347    0.183684\n",
       "1348    0.103604\n",
       "1349    0.106857\n",
       "Name: Gr Liv Area, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['Gr Liv Area'] #0~1 사이로 정규화가 된 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bac40c",
   "metadata": {},
   "source": [
    "### 모델 설계 & 학습\n",
    "\n",
    "#### GridSearchCV 를 사용한 파라미터 최적화\n",
    "\n",
    "이제 데이터를 전처리하는 과정이 끝났습니다. 이제 데이터 분석을 위해 모델을 설계하는 단계를 진행해야 합니다.\n",
    "\n",
    "우선 사용할 모델을 선택하여야 합니다. 사용할 모델은 데이터의 특성, task 의 특성에 알맞게 선택해야 합니다.\n",
    "\n",
    "모델을 선택했다면 모델의 파라미터를 최적화하는 과정을 거쳐야 합니다. \n",
    "\n",
    "파라미터란 모델의 설정을 말합니다. 예를 들어 Linear Regression 모델의 경우 y 절편을 0으로 설정할 수 있습니다.\n",
    "\n",
    "파라미터 최적화를 하는 기본적인 방법은 여러 파라미터들을 실험하는 방법입니다.\n",
    "\n",
    "sklearn 은 GridSearchCV 메소드를 제공합니다.\n",
    "\n",
    "우선 선택한 모델과 비교하고 싶은 파라미터들을 설정해 줍니다. \n",
    "\n",
    "그 다음 학습 데이터를 나누어줍니다. 예를 들어 학습 데이터를 5개의 배치로 나누어 주었다고 가정 해보겠습니다.\n",
    "\n",
    "5개로 나누어진 데이터 중, 4개의 데이터로 학습을 진행합니다. 그 다음 나머지 1개의 데이터 배치로 성능을 검증합니다.\n",
    "\n",
    "따라서 5번의 학습과 검증이 이루어질 것 입니다. 이때 최상의 성능을 출력하는 파라미터들이 모델의 파라미터로 선택되는 것 입니다.\n",
    "\n",
    "데이터를 n개의 배치로 나누고, 비교하고자 하는 파라미터들의 조합이 m개라면 총 n * m 번의 학습과 검증이 진행되는 것 입니다.\n",
    "\n",
    "따라서 학습 시간이 오래 걸리고, 그에 맞는 컴퓨팅 자원이 필요합니다.\n",
    "\n",
    "이번 베이스라인에서는 GridSearchCV 기법의 개념을 소개하는 방향으로 작성되었습니다.\n",
    "\n",
    "따라서 앙상블 기법에 사용된 세부적인 모델들의 세부적인 개념들을 추후 베이스라인들에서 소개하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46ec52",
   "metadata": {},
   "source": [
    "# RandomForestRegressor\n",
    "\n",
    "![title](img/img1.jpg)\n",
    "무작위로 의사 결정 트리(나무)를 다수 만들어서 숲을 만든다는 의미에서 무작위 숲(random forest)이라는 이름을 지은 것으로 추정된다.\n",
    "랜덤 포레스트는 데이터셋의 다양한 하위 샘플을 이용해서 다수의 \"분류 의사 결정 트리(classifying  decision tree)\"를 학습하는 메타 예측기(a meta estimator)다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b14657",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor\n",
    "\n",
    "![title](img/img2.jpg)\n",
    "앙상블 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가하지만 이전 예측기가 만든 잔여오차에 새로운 예측기를 학습시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c48c03",
   "metadata": {},
   "source": [
    "# ExtraTreesRegressor\n",
    "\n",
    "![title](img/img3.jpg)\n",
    "\n",
    "랜덤 포레스트 모델의 변종이다. 엑스트라 트리는 포레스트 트리의 각 후보 특성을 무작위로 분할하는 식으로 무작위성을 증가 시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97ccd75e-30d7-49ca-880e-86034bdd1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV 를 사용할 모델들을 호출합니다. ##회귀를 위한 다양한 모델들\n",
    "from sklearn.ensemble import RandomForestRegressor #랜덤포레스트 앙상블\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor #익스트림 랜덤 트리\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#모델들을 할당할 리스트를 만들어줍니다.\n",
    "estimators = []\n",
    "\n",
    "#estimators 리스트에 모델들을 추가해줍니다.\n",
    "rf = RandomForestRegressor()\n",
    "estimators.append(rf)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "estimators.append(gbr)\n",
    "\n",
    "etr = ExtraTreesRegressor()\n",
    "estimators.append(etr)\n",
    "\n",
    "#모들의 파라미터들을 할당할 리스트를 만들어줍니다.\n",
    "params = []\n",
    "\n",
    "# params 리스트에 성능을 비교하고자하는 파라미터들 추가해줍니다.\n",
    "params_rf = {'n_estimators' : [90, 100, 110, 120],\n",
    "            'min_samples_split' : [1,2,3,4]}\n",
    "params.append(params_rf)\n",
    "\n",
    "params_gbr = {'loss' : ['huber', 'quantile'],\n",
    "             'learning_rate':[0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15],\n",
    "             'n_estimators':[60,70,80,90,100,110,120,130,140,150]}\n",
    "params.append(params_gbr)\n",
    "\n",
    "params_etr = {'n_estimators' : [50,60,70,80,90,100,110,120,130,140,150]}\n",
    "params.append(params_etr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae20071a-34e4-47b9-acc6-31409c54a063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 220 candidates, totalling 1100 fits\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV 를 이용해 모델들을 최적화시켜줍니다.\n",
    "from tqdm.auto import tqdm\n",
    "def gridSearchCV(models,params):\n",
    "    best_models=[]\n",
    "    for i in tqdm(range(0,len(models))):\n",
    "        model_grid = GridSearchCV(models[i], params[i],n_jobs = -1, verbose=1, cv=5)\n",
    "        model_grid.fit(train_x,train_y)\n",
    "        best_models.append(model_grid.best_estimator_)\n",
    "    return best_models\n",
    "\n",
    "best_model_list = gridSearchCV(estimators,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c1b0370-4788-446a-bcd4-8e54fcd3b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestRegressor(min_samples_split=4, n_estimators=90),\n",
       " GradientBoostingRegressor(learning_rate=0.09, loss='huber', n_estimators=150),\n",
       " ExtraTreesRegressor(n_estimators=150)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSerachCV 를 통해 최적화된 모델들을 확인합니다.\n",
    "best_model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe36741-d655-4a3a-a06d-522a684d49d7",
   "metadata": {},
   "source": [
    "#### 앙상블 모델 학습\n",
    "\n",
    "위 코드에서는 3개의 모델을 선택하여 GridSearchCV 를 통해 각 모델들의 파라미터들을 최적화해주었습니다.\n",
    "\n",
    "그 다음에는 3개의 모델을 모두 활용하여 하나의 모델을 설계해 보겠습니다.\n",
    "\n",
    "앙살블 기법은 \"집단지성\" 으로 부터 아이디어를 얻은 알고리즘입니다.\n",
    " \n",
    "모델 하나의 예측 보다는 여러 모델들의 예측을 종합하여 도출한 예측이 더 정확할 때가 많습니다. \n",
    "\n",
    "Regression 의 경우 각 모델들이 개별로 예측한 값의 평균 값을 도출하는 방식으로 여러 모델들을 조합해줍니다.\n",
    "\n",
    "sklearn 패키지의 VotingRegressor 메소드를 통해 앙상블 모델을 구현할 수 있습니다.\n",
    "\n",
    "GridSearchCV 를 통해 최적의 파라미터들을 찾은 모델들 VotingRegressor 객체에 할당한 후, 학습을 진행합니다.\n",
    "\n",
    "이번 베이스라인에서는 앙상블 기법의 개념을 소개하는 방향으로 작성되었습니다.\n",
    "\n",
    "따라서 앙상블 기법에 사용된 세부적인 모델들의 세부적인 개념들을 추후 베이스라인들에서 소개하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19cc264b-70f5-4009-9650-a11fac507e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('rf',\n",
       "                             RandomForestRegressor(min_samples_split=4,\n",
       "                                                   n_estimators=90)),\n",
       "                            ('GBR',\n",
       "                             GradientBoostingRegressor(learning_rate=0.09,\n",
       "                                                       loss='huber',\n",
       "                                                       n_estimators=150)),\n",
       "                            ('ET', ExtraTreesRegressor(n_estimators=150))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV 를 통해 최적화된 모델들을 사용합니다.\n",
    "best_models = [\n",
    "    ('rf', RandomForestRegressor(min_samples_split=4, n_estimators=90)),\n",
    "    ('GBR', GradientBoostingRegressor(learning_rate=0.09, loss='huber', n_estimators=150)),\n",
    "    ('ET', ExtraTreesRegressor(n_estimators=150))\n",
    "] #위에서 만든 best_model_list를 참고해 값을 넣어줌\n",
    "\n",
    "#앙상블 기법을 위한 패키지를 불러옵니다.\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "#앙상블 모델을 학습시켜줍니다.\n",
    "voting_rg = VotingRegressor(estimators=best_models)\n",
    "voting_rg.fit(train_x,train_y) #학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca202e9-40ba-4250-bc1b-8faf0fbad273",
   "metadata": {},
   "source": [
    "### 추론\n",
    "\n",
    "학습 데이터에 했던 전처리 과정(라벨인코딩, 정규화)를 테스트 데이터에도 해줍니다.\n",
    "\n",
    "단, 학습 데이터에 학습된 인코더와 정규화 파라미터를 사용해 주어야 합니다. \n",
    "\n",
    "(테스트 데이터를 학습 시킨 후 인코딩과 정규화를 진행하면 data leakage 에 해당됩니다!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ace9085a-4598-4674-b3ea-f0e540e0ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터 전처리 과정\n",
    "\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "test_x = test_data.drop(\"id\",axis=1) #id는 필요없고 test data는 target이 없기 때문. ##target=우리가 예측해야 할 값\n",
    "\n",
    "for feature in cat_features:\n",
    "    test_x[feature] = le.transform(test_x[feature]) #위에서 한 문자형 데이터 수치화\n",
    "    \n",
    "test_x[num_features] = scaler.transform(test_x[num_features]) #위에서 한 수치형 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ea6a30c-1858-435d-b839-9d01bcaa3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습된 모델을 통해 test 데이터를 추론합니다.\n",
    "predictions = voting_rg.predict(test_x) #voting_rg=모델\n",
    "\n",
    "sample_submission.target = predictions\n",
    "sample_submission.to_csv(\"submission.csv\",index = False) #제출용 csv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe65ef8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>333938.174958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>129969.061908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>177000.724531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>242995.235781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>130705.608122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1346</td>\n",
       "      <td>317839.053218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1347</td>\n",
       "      <td>127424.558943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1348</td>\n",
       "      <td>85963.316717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1349</td>\n",
       "      <td>208450.666201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1350</td>\n",
       "      <td>147118.104160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         target\n",
       "0        1  333938.174958\n",
       "1        2  129969.061908\n",
       "2        3  177000.724531\n",
       "3        4  242995.235781\n",
       "4        5  130705.608122\n",
       "...    ...            ...\n",
       "1345  1346  317839.053218\n",
       "1346  1347  127424.558943\n",
       "1347  1348   85963.316717\n",
       "1348  1349  208450.666201\n",
       "1349  1350  147118.104160\n",
       "\n",
       "[1350 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
